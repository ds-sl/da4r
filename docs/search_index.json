[["index.html", "Data Analysis for Researchers About", " Data Analysis for Researchers DS SL 2022-10-10 About This is a lecture note of a course jointly taught in the Winter term AY2021. First we start with the contents of the slides and gradually include other contents into this book. "],["course.html", "Chapter 1 About the Course 1.1 Coures Information 1.2 Introduction by Professor Kaizoji 1.3 Introduction in AY2020 by Suzuki", " Chapter 1 About the Course 1.1 Coures Information 1.1.1 About ‘QALL401 Data Analysis for Researchers’ An introduction to data science (DS). It is an exploratory data analysis (EDA) that is an essential part of scientific research and an evidence-based decision making of a responsible global citizen. Students acquire the knowledge and learn the necessary principles for appropriate computer utilization in making research results public in order to communicate the outcomes. Since data science supports technologies of artificial intelligence, ethical issues are becoming more and more important. We introduce R, a widely used free software environment for statistical computing and graphics, and Rmarkdown, an authoring format that enables easy creation of dynamic documents, presentations, and reports from R, supporting reproducible research and literate programming. We will experience the process of data science and set a foundation to delovep data science skills and take time to think about the ethical issues of its outcomes. Instructors: Keisuke Ishibashi, Taisei Kaizoji and Hiroshi Suzuki Description: This course will help students from many academic fields develop skills to obtain necessary information from open data, as well as make charting and graphing for visualization. Students also learn fundamentals of data analysis and write short articles including data reasoning. The laboratory work uses open software such as R, and guest lectures on data analysis for research are included. Key Words: open data, data visualization, data analysis, data reasoning, R Features: laboratory work - practicum, write short articles, guest lectures 1.2 Introduction by Professor Kaizoji 1.2.1 Introduction (Slide Presentation 1) Necessity of Information Literacy and Statistical Analysis Big Data Big Data Five V’s: Volume, Velocity, Variety, Veracity, Value HADOOP A new generation of Open Data: US Government: DATA.GOV Google Public Data Explorer Youtube Video Our World in Data Our World in Data: COVID-19 Data Analysis: COVID-19 Community Mobility Reports Explanatory Data Analysis(EDA) Getting Data Visualizing the data Statistically analyzing Making new discoveries Statistical hypothesis testing Building up a hypothesis Getting data Analyzing the data Testing the hypothesis R-Project The R language is an open source and free software programming language for statistical analysis. The R language was created by Ross Ihaka and Robert Clifford Gentleman at the University of Auckland, New Zealand. It is now maintained and extended by the R Development Core Team. R programming for beginners - Why you should use R The R Graph Gallery Extensive statistical packages 1.2.2 Data Analytics / Data Science Overview (Slide Presentation 2) What is data science / data analytics? Extract knowledge from data for decision-making and/or understanding phenomena understanding phenomena : infer mechanism that generates the observed data decision-making: determine what action to obtain the optimal output from the observed data Examples Education Is early English learning effective? Medical Is COVID-19 Vaccine effective? Politics Was lockdown beneficial in decreasing the number of new cases in infection? How about the effect for economics? Business Does online personal ad increase the sales? How much? Climate Is increase of CO2 related to the temperature increase? Health Is carbohydrate restriction effective for diet? Sports Does sacrifice bunt increase the probability of game win? Understanding phenomena and making decisions based on data Make decisions based on assumptions without basis or a few examples Understanding phenomena and making decisions based on data, while leaving the mechanisms that cause the phenomena as a black box to some extent. Inductive reasoning Elucidate the mechanisms that cause phenomena and make decisions based on those mechanisms. Example of data science Kepler Infer the planetary orbits as ellipse from the observed data (Finding a phenomenon) Before Newton discovered universal gravitation. Nightingale Find that the main cause of death among soldiers was poor sanitation in hospitals by analyzing the data on dead and sick soldiers in the Crimean War. Reduced the mortality rate from 42% to 5% (Decision- making). Before the German bacteriologist Koch discovered that bacteria were the cause of infections. Why data science / data analytics? The following two movement put the data-science approach Increase of available data =&gt; Open data (Prof. Kaizoji) Increase of computational power that can process the above huge data ### R and R Studio The Comprehensive R Archive Network R Studio IDE 1.2.3 Schedule (tentative) 2021.12.08 Week 1 Guidance, R setup 2021.12.15 Week 2 Exploratory Data Analysis (EDA) 1 2021.12.22 Week 3 Exploratory Data Analysis (EDA) 2 2022.01.12 Week 4 Exploratory Data Analysis (EDA) 3 2022.01.19 Week 5: Exploratory Data Analysis (EDA) 4 2022.01.26 Week 6: Exploratory Data Analysis (EDA) 5 2022.02.02 Week 7 : Inference Statistics (Regression, hypothesis testing, classification, etc.) 1 2022.02.09 Week 8: Inference Statistics (Regression, hypothesis testing, classification, etc.) 2 2022.02.16 Week 9: Inference Statistics (Regression, hypothesis testing, classification, etc.) 3 2022.02.23 Week 10 : Project Presentation 1.2.4 Responses of Students I took an undergraduate R studio programming last year and did quite poorly. I am not very good with coding and I’m a bit out of practice with math so I had a very hard time with the class. I’m nervous about this course as programming isn’t my strong suit. But I figured I should give R studio and data analysis another try and enrolled in this class. For my bachelor thesis, I am studying the various political and social factors that influence vaccine hesitancy in the United States and Japan. A lot of my writing and research involves reading published statistical data about COVID-19 cases and COVID-19 vaccination rates. I don’t have to do any data gathering of my own for my bachelor’s thesis, but I believe I may need to for my master’s dissertation next year. I feel that the content that will be covered in this course will greatly help me learn how to navigate my own research and analysis of evidence next year. I also have one comment regarding the logistics of the class. When the professors wrote information on the whiteboard during the class, it was very difficult to see over Zoom. It was also hard to follow along with the content as we couldn’t see what was being written. Is there any way that a picture of the board can be taken and uploaded to Moodle after class, or for the professors to use an online writing tool and write on the screen of their laptops so everyone can see it instead? It was also hard to hear whenever someone would ask a question in the classroom as they did not turn their mic on to talk through Zoom and the question/answer was not repeated to the people in the Zoom call. I’m looking forward to this class! よろしくお願い致します。 I have no questions since it is still the first class but I am looking forward to learning R here. Have a wonderful week/weekend! I have an interest in getting to know the data aspects of the research, including how to best use R for data analysis. I always avoided R due to its syntax / programming / coding nature. But now, I feel I am in a position to learn it, even though it is available in Graphical User Interface format as SPSS/Stata, etc. So, I am lucky to have the chance to learn through this course. And glad to be able to learn R while studying for Masters in Public Economics at ICU. I have already downloaded R, and I am eagerly looking forward to learn it. I shall post any questions / comments I have in near future. EDIT: I have downloaded RStudio as well, as instructed during today’s lecture. Dear sensei This course will help for analyzing data of my research in ICU. The Knowledge which will gain from this course will help for my further academic development also. Thank you I decided to take this course because I am conducting a quantitative survey for my Master’s thesis and do not know how I should analyze my data since it has been a while since I have taken a course related to statistics. I hope that through this course I will be able to learn ways to analyze the data I have gathered and gain an understanding of using different data analyzing tools, such as R. Thank you so much for today’s lecture and I look forward to next week’s class. Regarding the Research presentation how could I find data which is not available in public data bases. Is it ok for we find some data from our country sources. I am very excited to have the opportunity to use R again in this class. I was a data science minor in undergrad, so I have much experience using R. However, I have not had much reason to use it for a while so this class gives me a good way to get back into it and refresh my memory. I hope I can find a way to use data analysis in R for my master’s thesis and gain inspiration from this class. I believe it is a very great tool with a variety of uses. I have no background in data science, so I am a very fresh beginner, but I was very intrigued to learn about the many ways data is a large part of our lives. Particularly the examples of how to use data sites were fascinating. I understand that using Rstudio will also maybe help me become more of a critical thinker. So far, I have used Rstudio before class as a very lovely computer calculator. I hope to apply R to humanitarian data research and make that connection, as I have steered clear of computer programming-based languages so far. I am hoping to become somewhat fluent by the end of this course. Thank you very much. Thank you for the lecture today. As a psychology major still in the undergraduate year I have never used R and have always used SPSS so I am looking forward to learning a new program. As I have heard from my graduate friends that R is better I was always unsure of why we started out with spss. It seems a little daunting as it looks like coding but it does seem a lot easier as you can automate the process once it has been typed out once. I was also wondering if I was allowed to go offline somedays and online somedays or would this cause any trouble? Through today’s class, I re-recognized the importance of data analysis in my research. I am looking forward to learning data analysis using useful softwares. As mentioned in class, understanding the mechanism is important in research of physics. Therefore, I want to acquire techniques that predict mechanism of phenomena from bunch of data. Thank you so much for your lecture today. R studio is a great software. It is not “instant” software like some other software I used, so I will try to learn more about it via your instruction. Could I have a question, please? For panel data, is R studio stronger than other software like STATA? Thank you The diagram in Ishibashi sensei’s explanation with the way data could be connected to predictions and interpreted to form hypothesis was interesting. I had been wondering where unsupervised learning sits because it is so different from supervised learning but seeing their general relation was useful. Thank you so much for introducing the R tool. Could the package be written by the individuals by using the R tool? Thank you very much to the three professors for their wonderful lectures! This semester, I will conduct the data analysis part of my graduation thesis, so this course will be very helpful to me. I hope I can master the use method of R, so that I can independently complete data analysis in the future. Thank you for the lecture today. I hope i can get familiar with R-code and use to analysis data in my research report. Thank you, Professors, for the intuitive instruction. Thank you for your efforts. I have a little experience with a few types of programming languages but R is the first time for me. I want to try my best for familiarizing data analysis using R. I missed the first class because not yet register the course. So, if it is allow I would like to join this course. I just watch the week 1 zoom video. I think, to be able to manipulating, analysis and presenting data in the way people can understand is important skill for researchers. In am interested to learn more on how to do that, and also to learn R language as one of tools to handle big data. I have question : for the class practice as mention, it will took data from public data. How about for the final project/paper for this course? First, I would like to thank the three professors for your patience and guidance, and I must apologize for my late submission of the comment, as I had submitted it incorrectly before，it will not happen again. Through the first week’s study, I generally understand the concept of data science, data analysis, the R-project, big data, and the way to find data resources. And I mainly focus on the content that researchers can achieve two objectives: understanding phenomena and decision-making through a series of activities such as data analysis, setting hypotheses (prediction), generating data models, and testing hypotheses (black boxes). 1.3 Introduction in AY2020 by Suzuki 1.3.1 Requirements and Grades Not Much The knowledge of college level linear algebra and calculus are helpful but not required Experience of computer programming is helpful but not required Important Empirical studies require asking questions and hands-on-activities Questions Interactive and creative activities Instructors will support your learning Use Moodle Collaboration and cooperation 1.3.1.1 Grades Class participation and online quizzes - 30 % Short paper: research proposal - 20 % Presentation - 10 % Final paper - 40 % 1.3.2 Data Science (DS) Data Analysis (EDA): The core of Data Science Statistical Analysis Statistics? Mathematics? Computer Science? DS is based on statistical theory and mathematics but an empirical study empirical: based on, concerned with, or verifiable by observation or experience rather than theory or pure logic Artificial Intelligence (AI): AI is a broad area Machine Learning (ML), Reinforcement Learning (RL), Deap Learning (DL) Recommendation system, development of medicine, public health issues, managements Ethical issues of AI Is AI a black box? DS supports the technology of AI as application 1.3.3 EDA by R Language and R Programming Reproducibility and literate programming Questions &gt; Data &gt; Exploration (Observation, Visualization and Modeling) * Communication Use R and R Studio, locally and online. Mainly use base R and tidyverse packages Introduce Public, Open Data and API 1.3.3.1 EDA (A diagram from R4DS by H.W. and G.G.) EDA from r4ds 1.3.4 Visualization in EDA Let’s look at examples. 1.3.4.1 Florence Nightingale (1820 – 1910) Florence Nightingale was an English social reformer, statistician and the founder of modern nursing. (wikipedia) Diagram of the Causes of Motality in the Army in the East Insights in Social History, Books and Research by Hugh Small Florence Nightingale’s Statistical Diagrams: https://www.york.ac.uk/depts/maths/histstat/small.htm Florence Nightingale Museum https://www.florence-nightingale.co.uk/learning/ Meet Miss Nightingale: https://www.florence-nightingale.co.uk/meet-miss-nightingale/ Book: A contribution to the sanitary history of the British army during the late war with Russia Project Gutenberg: Books by Nightingale, Florence Notes on Nursing: What It Is, and What It Is Not Nightingale: The Journal of the Data Visualization Society, Medium 1.3.4.2 Hans Rosling (1948 – 2017) Hans Rosling was a Swedish physician, academic, and public speaker. He was a professor of international health at Karolinska Institute[4] and was the co-founder and chairman of the Gapminder Foundation, which developed the Trendalyzer software system. (wikipedia) Books: Factfulness: Ten Reasons We’re Wrong About The World - And Why Things Are Better Than You Think, 2018 How I Learned to Understand the World: A Memoir, 2020 Gapminder: https://www.gapminder.org You are probably wrong about: Upgrade Your World View Bubble Chart: Income vs Life Expectancy over time, 1800 - 2020 How many variables? Videos: The best stats you’ve ever seen, Hans Rosling Google Public Data: Example: World Development Indicator 1.3.4.2.1 Factfulness is … From the book recognizing when a decision feels urgent and remembering that it rarely is. To control the urgency instinct, take small steps. Take a breath. When your urgency instinct is triggered, your other instincts kick in and your analysis shuts down. Ask for more time and more information. It’s rarely now or never and it’s rarely either/or. Insist on the data. If something is urgent and important, it should be measured. Beware of data that is relevant but inaccurate, or accurate but irrelevant. Only relevant and accurate data is useful. Beware of fortune-tellers. Any prediction about the future is uncertain. Be wary of predictions that fail to acknowledge that. Insist on a full range of scenarios, never just the best or worst case. Ask how often such predictions have been right before. Be wary of drastic action. Ask what the side effects will be. Ask how the idea has been tested. Step-by-step practical improvements, and evaluation of their impact, are less dramatic but usually more effective. 1.3.5 Data Science (Wikipedia) An inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from many structural and unstructured data. Data science is related to data mining, machine learning and big data. A “concept to unify statistics, data analysis and their related methods” in order to “understand and analyze actual phenomena” with data. It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, domain knowledge and information science. Turing award winner Jim Gray imagined data science as a “fourth paradigm” of science (empirical, theoretical, computational and now data-driven) and asserted that “everything about science is changing because of the impact of information technology” and the data deluge. 1.3.6 Data for Data Science 1.3.6.1 We will use: Create a small dataset to understand the operations, and a reasonably large dataset by a simulation Collection of datasets attached to R and packages ready for EDA Real world data - open, public data 1.3.6.2 For data or chart representing statistical data Find the source of data Find the definitions and metadata of the data How is the data collected? What does each variable represent? Can we use it withtout permission? Ask questions What does the data tell us? Related questions? For evidence based data analysis leading to extract knowledge and insights for decision making. 1.3.7 Open and Public Data 1.3.7.1 World Bank: Open Data Defined The term ``Open Data’’ has a very precise meaning. Data or content is open if anyone is free to use, re-use or redistribute it, subject at most to measures that preserve provenance and openness. The data must be , which means they must be placed in the public domain or under liberal terms of use with minimal restrictions. The data must be , which means they must be published in electronic formats that are machine readable and non-proprietary, so that anyone can access and use the data using common, freely available software tools. Data must also be publicly available and accessible on a public server, without password or firewall restrictions. To make Open Data easier to find, most organizations create and manage Open Data catalogs. 1.3.8 A List of Open Data Catalogue 1.3.8.1 International Institutions World Bank: New Ways of Looking at Poverty Open Data: https://data.worldbank.org World Development Indicators: http://datatopics.worldbank.org/world-development-indicators/ UN Data: http://data.un.org WHO Data: https://www.who.int/gho/en/ OECD: https://data.oecd.org European Union: http://data.europa.eu/euodp/en/home African Union: https://au.int/en/ea/statistics 1.3.8.2 Goverments United States: https://www.data.gov United Kingdom: https://data.gov.uk China: http://www.stats.gov.cn/english/ Japan: https://www.data.go.jp/list-of-database/?lang=en 1.3.8.3 Other Open Public Data Google Public Data Explore: https://www.google.com/publicdata/directory?hl=en_US Google Dataset Search: https://toolbox.google.com/datasetsearch Google Trends: https://trends.google.com/trends/?geo=US Open Knowledge Foundation: https://okfn.org Global Open Data Index: https://index.okfn.org A global, non-profit network that promotes and shares information at no charge, including both content and data. It was founded by Rufus Pollock on 20 May 2004 and launched on 24 May 2004 in Cambridge, UK. It is incorporated in England and Wales as a company limited by guarantee. (Wikipedia) Our World in Data: https://ourworldindata.org A scientific online publication that focuses on large global problems such as poverty, disease, hunger, climate change, war, existential risks, and inequality. The publication’s founder is the social historian and development economist Max Roser. The research team is based at the University of Oxford. (Wikipedia) 1.3.9 What is DS? Why DS? For researchers? Creation of Values Starts from Good Questions 1.3.9.1 Covid-19 JHU: https://coronavirus.jhu.edu/map.html WHO: https://covid19.who.int Our World in Data: https://ourworldindata.org/coronavirus jag-Japan: Toyo Keizai: https://toyokeizai.net/sp/visual/tko/covid19/en.html Public Health On Call: https://www.jhsph.edu/podcasts/public-health-on-call/ 001 001 - Global Preparedness, Misinformation and Community Transmission 2019 Global Health Security Index https://www.ghsindex.org Menu: Country Ranking 1.3.10 The First Step: Type of Variables What are varibles? How many variables? Quantitative variable? Qualitative variable? Numerical variable? Categorical variable? In R, there are six types: Double Integer Character Logical Raw Complex Study a, b, c, d carefully. 0, 1, 2, … can be double, integer, character, and logical symbols T and F can be computed as 1 and 0 "],["eda1.html", "Chapter 2 Exploratory Data Analysis (EDA) 1 2.1 R with R Studio and/or R Studio.cloud 2.2 Practicum: Swirl and more on R Script", " Chapter 2 Exploratory Data Analysis (EDA) 1 2.1 R with R Studio and/or R Studio.cloud 2.1.1 Course Contents 2020-12-08: Introduction: About the course - An introduction to open and public data, and data science 2020-12-15: Exploratory Data Analysis (EDA) 1 [lead by hs] - R Basics with RStudio and/or RStudio.cloud; R Script, swirl 2021-12-22: Exploratory Data Analysis (EDA) 2 [lead by hs] - R Markdown; Introduction to tidyverse; RStudio Primers 2022-01-12: Exploratory Data Analysis (EDA) 3 [lead by hs] - Introduction to tidyverse; Public Data, WDI, etc 2022-01-19: Exploratory Data Analysis (EDA) 4 [lead by hs] - Introduction to tidyverse; WDI, UN, WHO, etc 2022-01-26: Exploratory Data Analysis (EDA) 5 [lead by hs] - Introduction to tidyverse; WDI, OECD, US gov, etc 2022-02-02: Inference Statistics 1 2022-02-09: Inference Statistics 2 2022-02-16: Inference Statistics 3 2022-02-23: Project Presentation 2.1.2 Learning Resources, I 2.1.2.1 Textbooks “R for Data Science” by Hadley Wickham and Garrett Grolemund: Free Online Book: https://r4ds.had.co.nz “R for Data Science: Exercise Solutions” by Jeffrey B. Arnold Free Online Book: https://jrnold.github.io/r4ds-exercise-solutions/ 2.1.2.2 Other Resources (MOOCs) edX: HarvardX Data Science - 9 courses. Textbook: “Introduction to Data Science” by Rafael A. Irizarry. Free Online Book by Rafael A. Irizarry. coursera: JHU Data Science - 10 courses. List of Companion Books: “R Programming for Data Science” by Roger Peng. Free Online Book by Roger Peng. “Exploratory Data Analysis with R” by Roger Peng. Free online Book by Roger Peng. “Report Writing for Data Science in R” by Roger Peng “Statistical Inference for Data Science” by Brian Caffo “Regression Modeling for Data Science in R” by Brian Caffo 2.1.3 EDA1: Contents What is R? Why R? the First Example What is R Studio and R Studio Cloud? Installation of R and R Studio   R Studio Basics R Studio Cloud Basics Project, R Console R Basics using an R Script {swirl}: Learn R, in R EDA: Coronavirus, the first example Assignment 1 and Assignment 2 in Moodle 2.1.4 What is R? 2.1.4.1 R (programming language), Wikipedia R is a programming language and free software environment for statistical computing and graphics supported by the R Foundation for Statistical Computing. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. A GNU package, the official R software environment is written primarily in C, Fortran, and R itself (thus, it is partially self-hosting) and is freely available under the GNU General Public License. 2.1.4.2 History of R and more “R Programming for Data Science” by Roger Peng Chapter 2. History and Overview of R Overview and History of R: Youtube video 2.1.5 Why R? – Responses by Hadley Wickham 2.1.5.1 r4ds: R is a great place to start your data science journey because R is an environment designed from the ground up to support data science. R is not just a programming language, but it is also an interactive environment for doing data science. To support interaction, R is a much more flexible language than many of its peers. 2.1.5.2 Why R today? When you talk about choosing programming languages, I always say you shouldn’t pick them based on technical merits, but rather pick them based on the community. And I think the R community is like really, really strong, vibrant, free, welcoming, and embraces a wide range of domains. So, if there are like people like you using R, then your life is going to be much easier. That’s the first reason. Interview: “Advice to Young (and Old) Programmers, H. Wickham” 2.1.6 The First Example plot(cars) plot(cars) # cars: Speed and Stopping Distances of Cars abline(lm(cars$dist~cars$speed)) head(cars) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 7 22 ## 5 8 16 ## 6 9 10 summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 summary(lm(cars$dist~cars$speed)) ## ## Call: ## lm(formula = cars$dist ~ cars$speed) ## ## Residuals: ## Min 1Q Median 3Q Max ## -29.069 -9.525 -2.272 9.215 43.201 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -17.5791 6.7584 -2.601 0.0123 * ## cars$speed 3.9324 0.4155 9.464 1.49e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.38 on 48 degrees of freedom ## Multiple R-squared: 0.6511, Adjusted R-squared: 0.6438 ## F-statistic: 89.57 on 1 and 48 DF, p-value: 1.49e-12 2.1.7 What is RStudio? https://rstudio.com RStudio is an integrated development environment, or IDE, for R programming. 2.1.7.1 R Studio (Wikipedia) RStudio is an integrated development environment (IDE) for R, a programming language for statistical computing and graphics. It is available in two formats: RStudio Desktop is a regular desktop application while RStudio Server runs on a remote server and allows accessing RStudio using a web browser. 2.1.7.2 R Studio Cloud https://rstudio.cloud RStudio Cloud is a lightweight, cloud-based solution that allows anyone to do, share, teach and learn data science online. 2.1.8 Installation of R and R Studio 2.1.8.1 R Installation To download R, go to CRAN, the comprehensive R archive network. CRAN is composed of a set of mirror servers distributed around the world and is used to distribute R and R packages. Don’t try and pick a mirror that’s close to you: instead use the cloud mirror, https://cloud.r-project.org, which automatically figures it out for you. A new major version of R comes out once a year, and there are 2-3 minor releases each year. It’s a good idea to update regularly. 2.1.8.2 R Studio Installation Download and install it from http://www.rstudio.com/download. RStudio is updated a couple of times a year. When a new version is available, RStudio will let you know. 2.1.9 R Studio 2.1.9.1 The First Step Start R Studio Application Top Menu: File &gt; New Project &gt; New Directory &gt; New Project &gt; Directory name or Browse the directory and choose the parent directory you want to create the directory 2.1.9.2 When You Start the Project Go to the directory you created Double click _‘Directory Name’.Rproj Or, Start R Studio File &gt; Open Project (or choose from Recent Project) In this way the working directory of the session is set to the project directory and R can search releted files without difficulty (getwd(), setwd()) 2.1.10 R Studio Cloud 2.1.10.1 Cloud Free Up to 15 projects total 1 shared space (5 members and 10 projects max) 15 project hours per month Up to 1 GB RAM per project Up to 1 CPU per project Up to 1 hour background execution time 2.1.10.2 How to Start R Studio Cloud Go to https://rstudio.cloud/ Sign Up: top right Email address or Google account New Project: Project Name R Console 2.1.11 Let’s Try R Basics 2.1.11.1 R Basics Let’s Try R on R Studio and/or R Studio Cloud 2.1.11.2 R Scripts Copy a script in Moodle: basics.R In RStudio (Workspace in RStudio.cloud, Project in RStudio) choose File &gt; New File &gt; R Script and paste it. Choose File &gt; Save with a name; e.g. basics (.R will be added automatically) 2.1.11.3 Helpful Resources Cheet Sheet in RStudio: https://www.rstudio.com/resources/cheatsheets/ RStudio IED Base R Cheat Sheet ‘Quick R’ by DataCamp: https://www.statmethods.net/management 2.1.12 More on R Script: Examples 2.1.12.1 R Scripts in Moodle basics.R coronavirus.R Copy a script in Moodle: {file name}.R In RStudio (Workspace in RStudio.cloud, Project in RStudio) choose File &gt; New File &gt; R Script and paste it. Choose File &gt; Save with a name; e.g. {file names} (.R will be added automatically) 2.1.13 Practicum: R Studio Cloud (or R Studio) and R basics 2.1.13.1 Let’s Try R Basics R Studio Cloud Create an account Create a Project R Studio Basics R Basics basics.R 2.1.13.2 Basics.R The script with the outputs. ################# # # basics.R # ################ # &#39;Quick R&#39; by DataCamp may be a handy reference: # https://www.statmethods.net/management/index.html # Cheat Sheet at RStudio: https://www.rstudio.com/resources/cheatsheets/ # Base R Cheat Sheet: https://github.com/rstudio/cheatsheets/raw/main/base-r.pdf # To execute the line: Control + Enter (Window and Linux), Command + Enter (Mac) ## try your experiments on the console ## calculator 3 + 7 ## [1] 10 ### +, -, *, /, ^ (or **), %%, %/% 3 + 10 / 2 ## [1] 8 3^2 ## [1] 9 2^3 ## [1] 8 2*2*2 ## [1] 8 ### assignment: &lt;-, (=, -&gt;, assign()) x &lt;- 5 x ## [1] 5 #### object_name &lt;- value, &#39;&lt;-&#39; shortcut: Alt (option) + &#39;-&#39; (hyphen or minus) #### Object names must start with a letter and can only contain letter, numbers, _ and . this_is_a_long_name &lt;- 5^3 this_is_a_long_name ## [1] 125 char_name &lt;- &quot;What is your name?&quot; char_name ## [1] &quot;What is your name?&quot; #### Use &#39;tab completion&#39; and &#39;up arrow&#39; ### ls(): list of all assignments ls() ## [1] &quot;char_name&quot; &quot;this_is_a_long_name&quot; &quot;x&quot; ls.str() ## char_name : chr &quot;What is your name?&quot; ## this_is_a_long_name : num 125 ## x : num 5 #### check Environment in the upper right pane ### (atomic) vectors 5:10 ## [1] 5 6 7 8 9 10 a &lt;- seq(5,10) a ## [1] 5 6 7 8 9 10 b &lt;- 5:10 identical(a,b) ## [1] TRUE seq(5,10,2) # same ase seq(from = 5, to = 10, by = 2) ## [1] 5 7 9 c1 &lt;- seq(0,100, by = 10) c2 &lt;- seq(0,100, length.out = 10) c1 ## [1] 0 10 20 30 40 50 60 70 80 90 100 c2 ## [1] 0.00000 11.11111 22.22222 33.33333 44.44444 55.55556 66.66667 ## [8] 77.77778 88.88889 100.00000 length(c1) ## [1] 11 #### ? seq ? length ? identical (die &lt;- 1:6) ## [1] 1 2 3 4 5 6 zero_one &lt;- c(0,1) # same as 0:1 die + zero_one # c(1,2,3,4,5,6) + c(0,1). re-use ## [1] 1 3 3 5 5 7 d1 &lt;- rep(1:3,2) # repeat d1 ## [1] 1 2 3 1 2 3 die == d1 ## [1] TRUE TRUE TRUE FALSE FALSE FALSE d2 &lt;- as.character(die == d1) d2 ## [1] &quot;TRUE&quot; &quot;TRUE&quot; &quot;TRUE&quot; &quot;FALSE&quot; &quot;FALSE&quot; &quot;FALSE&quot; d3 &lt;- as.numeric(die == d1) d3 ## [1] 1 1 1 0 0 0 ### class() for class and typeof() for mode ### class of vectors: numeric, charcters, logical ### types of vectors: doubles, integers, characters, logicals (complex and raw) typeof(d1); class(d1) ## [1] &quot;integer&quot; ## [1] &quot;integer&quot; typeof(d2); class(d2) ## [1] &quot;character&quot; ## [1] &quot;character&quot; typeof(d3); class(d3) ## [1] &quot;double&quot; ## [1] &quot;numeric&quot; sqrt(2) ## [1] 1.414214 sqrt(2)^2 ## [1] 2 sqrt(2)^2 - 2 ## [1] 4.440892e-16 typeof(sqrt(2)) ## [1] &quot;double&quot; typeof(2) ## [1] &quot;double&quot; typeof(2L) ## [1] &quot;integer&quot; 5 == c(5) ## [1] TRUE length(5) ## [1] 1 ### Subsetting (A_Z &lt;- LETTERS) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; &quot;K&quot; &quot;L&quot; &quot;M&quot; &quot;N&quot; &quot;O&quot; &quot;P&quot; &quot;Q&quot; &quot;R&quot; &quot;S&quot; ## [20] &quot;T&quot; &quot;U&quot; &quot;V&quot; &quot;W&quot; &quot;X&quot; &quot;Y&quot; &quot;Z&quot; A_F &lt;- A_Z[1:6] A_F ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; A_F[3] ## [1] &quot;C&quot; A_F[c(3,5)] ## [1] &quot;C&quot; &quot;E&quot; large &lt;- die &gt; 3 large ## [1] FALSE FALSE FALSE TRUE TRUE TRUE even &lt;- die %in% c(2,4,6) even ## [1] FALSE TRUE FALSE TRUE FALSE TRUE A_F[large] ## [1] &quot;D&quot; &quot;E&quot; &quot;F&quot; A_F[even] ## [1] &quot;B&quot; &quot;D&quot; &quot;F&quot; A_F[die &lt; 4] ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; ### Compare df with df1 &lt;- data.frame(number = die, alphabet = A_F) df &lt;- data.frame(number = die, alphabet = A_F, stringsAsFactors = FALSE) df ## number alphabet ## 1 1 A ## 2 2 B ## 3 3 C ## 4 4 D ## 5 5 E ## 6 6 F df$number ## [1] 1 2 3 4 5 6 df$alphabet ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; df[3,2] ## [1] &quot;C&quot; df[4,1] ## [1] 4 df[1] ## number ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 class(df[1]) ## [1] &quot;data.frame&quot; class(df[[1]]) ## [1] &quot;integer&quot; identical(df[[1]], die) ## [1] TRUE identical(df[1],die) ## [1] FALSE #################### # The First Example #################### plot(cars) # Help ? cars # cars is in the &#39;datasets&#39; package data() # help(cars) does the same as ? cars # You can use Help tab in the right bottom pane help(plot) ## トピック &#39;plot&#39; に対するヘルプが以下のパッケージ中にありました: ## ## Package Library ## graphics /Library/Frameworks/R.framework/Versions/4.2/Resources/library ## base /Library/Frameworks/R.framework/Resources/library ## ## ## 最初にマッチしたものを使っています ... ? par head(cars) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 7 22 ## 5 8 16 ## 6 9 10 str(cars) ## &#39;data.frame&#39;: 50 obs. of 2 variables: ## $ speed: num 4 4 7 7 8 9 10 10 10 11 ... ## $ dist : num 2 10 4 22 16 10 18 26 34 17 ... summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 x &lt;- cars$speed y &lt;- cars$dist min(x) ## [1] 4 mean(x) ## [1] 15.4 quantile(x) ## 0% 25% 50% 75% 100% ## 4 12 15 19 25 plot(cars) abline(lm(cars$dist ~ cars$speed)) summary(lm(cars$dist ~ cars$speed)) ## ## Call: ## lm(formula = cars$dist ~ cars$speed) ## ## Residuals: ## Min 1Q Median 3Q Max ## -29.069 -9.525 -2.272 9.215 43.201 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -17.5791 6.7584 -2.601 0.0123 * ## cars$speed 3.9324 0.4155 9.464 1.49e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.38 on 48 degrees of freedom ## Multiple R-squared: 0.6511, Adjusted R-squared: 0.6438 ## F-statistic: 89.57 on 1 and 48 DF, p-value: 1.49e-12 boxplot(cars) hist(cars$speed) hist(cars$dist) hist(cars$dist, breaks = seq(0,120, 10)) 2.1.13.3 Basic Reference An Introduction to R 2.2 Practicum: Swirl and more on R Script 2.2.1 Swirl: An interactive learning environment for R and statistics {swirl} website: https://swirlstats.com JHU Data Science in coursera uses swirl for exercises. 2.2.1.1 Swirl Courses R Programming: The basics of programming in R Regression Models: The basics of regression modeling in R Statistical Inference: The basics of statistical inference in R Exploratory Data Analysis: The basics of exploring data in R You can install other swirl courses as well Swirl Courses Organized by Title Swirl Courses Organized by Author’s Name Github: swirl courses install_course(\"Course Name Here\") 2.2.2 Install and Start Swirl Courses 2.2.2.1 Three Steps to Start Swirl install.packages(&quot;swirl&quot;) # Only the first time. library(swirl) # Everytime you start swirl swirl() # Everytime you start or resume swirl 2.2.2.2 R Programming: The basics of programming in R 1: Basic Building Blocks 2: Workspace and Files 3: Sequences of Numbers 4: Vectors 5: Missing Values 6: Subsetting Vectors 7: Matrices and Data Frames 8: Logic 9: Functions 10: lapply and sapply 11: vapply and tapply 12: Looking at Data 13: Simulation 14: Dates and Times 15: Base Graphics 2.2.2.3 Recommended Sections in Order 1, 3, 4, 5, 6, 7, 12, 15, 14, 8, 9, 10, 11, 13, 2 Section 2 discusses the directories and file systems of a computer Sections 9, 10, 11 are for programming 2.2.2.4 Controling a swirl Session … &lt;– That’s your cue to press Enter to continue You can exit swirl and return to the R prompt (&gt;) at any time by pressing the Esc key. If you are already at the prompt, type bye() to exit and save your progress. When you exit properly, you’ll see a short message letting you know you’ve done so. When you are at the R prompt (&gt;): Typing skip() allows you to skip the current question. Typing play() lets you experiment with R on your own; swirl will ignore what you do… UNTIL you type nxt() which will regain swirl’s attention. Typing bye() causes swirl to exit. Your progress will be saved. Typing main() returns you to swirl’s main menu. Typing info() displays these options again. 2.2.3 The First EDA using coronavirus.R Pre-installed datasets R Script To access shortcuts, type Option + Shift + K on a Mac, or Alt + Shift + K on Linux and Windows. EDA (A diagram from R4DS by H.W. and G.G.) 2.2.4 Basics of Fundamentals of Statistics 2.2.4.1 R Commands Related to R Basics Fundamentals of Statistics: statistical measurements such as mean: mean() or mean(x, na.rm = TRUE) median: median() or median(x, na.rm = TRUE) quantile: quantile() or quantile(x, na.rm = TRUE) variance: var() or var(x, na.rm = TRUE) standard deviation: sd() covariance: cov() correlation: cor() summary() 2.2.5 Summary 2.2.5.1 Please check the following Installation of R Installation of R Studio Login to RStudio.cloud swirl: R Programming Try 1, 3, 4, 5, 6, 7, 12, 15 R Script basics.R - try similar commands coronavirus.R - try different Regions and Periods 2.2.5.2 coronavirus.R The script and its outputs. coronavirus.csv is too large # https://coronavirus.jhu.edu/map.html # JHU Covid-19 global time series data # See R pakage coronavirus at: https://github.com/RamiKrispin/coronavirus # Data taken from: https://github.com/RamiKrispin/coronavirus/tree/master/csv # Last Updated Sys.Date() ## Download and read csv (comma separated value) file coronavirus &lt;- read.csv(&quot;https://github.com/RamiKrispin/coronavirus/raw/master/csv/coronavirus.csv&quot;) write.csv(coronavirus, &quot;data/coronavirus.csv&quot;) ## Summaries and structures of the data head(coronavirus) str(coronavirus) coronavirus$date &lt;- as.Date(coronavirus$date) str(coronavirus) range(coronavirus$date) unique(coronavirus$country) unique(coronavirus$type) ## Set Country COUNTRY &lt;- &quot;Japan&quot; df0 &lt;- coronavirus[coronavirus$country == COUNTRY,] head(df0) tail(df0) (pop &lt;- df0$population[1]) df &lt;- df0[c(1,6,7,13)] str(df) head(df) ### alternatively, head(df0[c(&quot;date&quot;, &quot;type&quot;, &quot;cases&quot;, &quot;population&quot;)]) ### ## Set types df_confirmed &lt;- df[df$type == &quot;confirmed&quot;,] df_death &lt;- df[df$type == &quot;death&quot;,] df_recovery &lt;- df[df$data_type == &quot;recovery&quot;,] head(df_confirmed) head(df_death) head(df_recovery) ## Histogram plot(df_confirmed$date, df_confirmed$cases, type = &quot;h&quot;) plot(df_death$date, df_death$cases, type = &quot;h&quot;) # plot(df_recovered$date, df_recovered$cases, type = &quot;h&quot;) # no data for recovery ## Scatter plot and correlation plot(df_confirmed$cases, df_death$cases, type = &quot;p&quot;) cor(df_confirmed$cases, df_death$cases) ## In addition set a period start_date &lt;- as.Date(&quot;2021-07-01&quot;) end_date &lt;- Sys.Date() df_date &lt;- df[df$date &gt;=start_date &amp; df$date &lt;= end_date,] ## ## Set types df_date_confirmed &lt;- df_date[df_date$type == &quot;confirmed&quot;,] df_date_death &lt;- df_date[df_date$type == &quot;death&quot;,] df_date_recovery &lt;- df_date[df_date$data_type == &quot;recovery&quot;,] head(df_date_confirmed) head(df_date_death) head(df_date_recovery) ## Histogram plot(df_date_confirmed$date, df_date_confirmed$cases, type = &quot;h&quot;) plot(df_date_death$date, df_date_death$cases, type = &quot;h&quot;) # plot(df_date_recovered$date, df_date_recovered$cases, type = &quot;h&quot;) # no data for recovery plot(df_date_confirmed$cases, df_date_death$cases, type = &quot;p&quot;) cor(df_date_confirmed$cases, df_date_death$cases) ### Q0. Change the values of the location and the period and see the outcomes. ### Q1. What is the correlation between df_confirmed$cases and df_death$cases? ### Q2. Do we have a larger correlation value if we shift the dates to implement the time-lag? ### Q3. Do you have any other questions to explore? #### Extra plot(df_confirmed$date, df_confirmed$cases, type = &quot;h&quot;, main = paste(&quot;Comfirmed Cases in&quot;,COUNTRY), xlab = &quot;Date&quot;, ylab = &quot;Number of Cases&quot;) 2.2.5.3 Assignment 1 and Assignment 2: Questions and a Quiz in Moodle Please complete assignments in Moodle by 2021-12-21 "],["eda2.html", "Chapter 3 Exploratory Data Analysis (EDA) 2 3.1 Part I: R Markdown for Communication 3.2 Part II: Data Visualization and Tidyverse Package 3.3 The Week Three Assignment (in Moodle) 3.4 Responses to the Week Three Assignment", " Chapter 3 Exploratory Data Analysis (EDA) 2 Course Contents 2021-12-08: Introduction: About the course - An introduction to open and public data, and data science 2021-12-15: Exploratory Data Analysis (EDA) 1 [lead by hs] - R Basics with RStudio and/or RStudio.cloud; R Script, swirl 2021-12-22: Exploratory Data Analysis (EDA) 2 [lead by hs] - R Markdown; Introduction to tidyverse; RStudio Primers 2022-01-12: Exploratory Data Analysis (EDA) 3 [lead by hs] - Introduction to tidyverse; Public Data, WDI, etc 2022-01-19: Exploratory Data Analysis (EDA) 4 [lead by hs] - Introduction to tidyverse; WDI, UN, WHO, etc 2022-01-26: Exploratory Data Analysis (EDA) 5 [lead by hs] - Introduction to tidyverse; WDI, OECD, US gov, etc 2022-02-02: Inference Statistics 1 2022-02-09: Inference Statistics 2 2022-02-16: Inference Statistics 3 2022-02-23: Project Presentation EDA and Data Visualization Communication in the EDA Cycle Data Visualization in the EDA Cycle Tidyverse Package centered at ggplot2 EDA (A diagram from R4DS by H.W. and G.G.) EDA from r4ds Contents of EDA2 Reproducible Research Literate Programming R Markdown R Notebook Formats HTML pdf MS Word Presentation and more Practicum I: R Markdown and R Notebook Introduction to tidyverse package ggplot2 ggplot(), aes(), geoms, etc. Practicum II: tidyverse, ggplot2 on R Notebook Learning Resources: RStuido Primers, etc. 3.1 Part I: R Markdown for Communication 3.1.1 Records of EDA and Communication Memo on scratch paper: R Scripts Record on a notebook: R Notebook (a type of an R Markdown format) Short paper or a digital communication: R Notebook Paper or a report: R Markdown (html, pdf, or MS Word) Presentation R Markdown with a presentation format (html, pdf, or PowerPoint) Publication of a Book BOOKDOWN: Write HTML, PDF, ePub, and Kindle books with R Markdown. Free online document is provided in pdf as well Arxive Page 3.1.2 What is R Markdown Notebook R Markdown provides an authoring framework for data science. You can use a single R Markdown file to both save and execute code generate high quality reports that can be shared with an audience R Notebooks are an implementation of Literate Programming that allows for direct interaction with R while producing a reproducible document with publication-quality output. An R Notebook is an R Markdown document with chunks that can be executed independently and interactively, with output visible immediately beneath the input. (Reference: R Markdown: The Definitive Guide, 3.2 Notebook) 3.1.3 R Studio Setup Start R Studio Create a Project Tool &gt; Install Packages rmarkdown Or on Console: install.packages(\"rmarkdown\") Tool &gt; Install Packages tinytex (for pdf generation) Let’s try! File &gt; New File &gt; R Notebook Save with a file name, say, test-notebook Preview by [Preview] button Run Code Chunk plot(cars) and then Preview again. Knit PDF, Word (and HTML) Note: R Notebooks are relatively new feature of RStudio and are only available in version 1.0 or higher of RStudio. 3.1.4 Default YAML: R Notebook, HTML, PDF, WORD --- title: &quot;The Title of This R Notebook&quot; author: &quot;Your Name&quot; date: &quot;2021-12-22&quot; output: html_notebook: default html_document: default word_document: default pdf_document: default --- Original format is output: html_document Indention matters in YAML. So it is safer to copy and paste output: to pdf_document: default R Notebook is also an HTML format, so html_notebook part may disappear after knitting in HTML. 3.1.5 An Example of R Notebooks Moodle: QALL401 2021W 2021-12-22 Examples of R Notebook Open the file R Codes with Outputs Headings, Links, Explanations, etc. [Hide] button, and [Code] button with a menu Choose: Download Rmd Save as “file_name.nb.html” in your R project directory Download and Save “jhu_covid.Rmd”. (Or, open the file in editor) Preview by [Preview] button. Knit to other formats, e.g. Word under [Preview] button N.B. If Step 4 does not work, create a new R Notebook and copy and paste [R Markdown Source File] in Moodle 3.1.6 Knit, Notebook Mode and Preview of Default.Rmd Knit to HTML Knit to PDF (require  system, install tinytex package) Knit to Word Controlling a code chunk and its output Highlight and run Run all chunks above Expand, collapse and clear output Show output in other window Modify chunk options Output Options: Notebook, HTML, PDF, Word General, Figures and Advanced 3.1.7 yaml - YAML Ain’t a Markup Language - Example --- title: &quot;File Name --Subtitle--&quot; author: &quot;My Name&quot; date: &quot;2021/12/22&quot; output: html_notebook: number_sections: yes toc: yes toc_float: yes word_document: fig_caption: yes fig_height: 5 fig_width: 6 # reference_docx: word-styles-reference-01.docx --- 3.1.8 R Markdown: Quick References (See Moodle) R Studio Help (menu bar) &gt; Markdown Quick Reference R Studio Help (menu bar) &gt; Cheat Sheet R Markdown Cheat Sheet R Markdown Reference Guide R Markdown: The Definitive Guide by Yihui Xie, J. J. Allaire, Garrett Grolemund In Textbook: R for Data Science: Communicate Markdown: R Markdown is based on the Markdown language of Pandoc Pandoc’s Markdown: Detailed Information Markdown Tutorials: Interactive Practicum DARING FIREBALL: Markdown (detailed explanation and editor as Dingus) 3.1.9 Markdown Language – or use WYSIWYG editor Headers: #, ##, ###, #### Lists: 1. 2. , * Links: linked phrase Images: ![alt text](figures/filename.jpg) Block quotes” &gt; (block)   equations: e.g. $\\frac{a}{b}$ for \\(\\frac{a}{b}\\) Horizontal rules: Three or more asterisks or dashes (*** or - - - ) Tables Footnotes Bibliographies and Citations Slide breaks Italicized text by _italic_, Bold text by **bold** Superscripts, Subscripts, Strikethrough text 3.1.10 MS Word: Happy collaboration with Rmd to docx Use R Markdown to create a Word document Save as: ``word-styles-reference-01.docx’’ Edit the Word styles Edit the styles of the file ``word-styles-reference-01.docx’’ . Save this document as your style reference docx file Format an Rmd report using the styles reference docx file --- title: &quot;Test Report&quot; author: &quot;Your Name&quot; date: &quot;January 6, 2021&quot; output: word_document: reference_docx: word-styles-reference-01.docx --- 3.1.11 Why R Markdown? 3.1.11.1 R Markdown Cheat Sheet .Rmd files: An R Markdown (.Rmd) file is a record of your research. It contains the code that a scientist needs to reproduce your work along with the narration that a reader needs to understand your work. Reproducible Research: At the click of a button, or the type of a command, you can rerun the code in an R Markdown file to Rmd reproduce your work and export the results as a finished report. Dynamic Documents: You can choose to export the finished report as a html, nb.html, pdf, MS Word, ODT, RTF, or markdown document; or as a html or pdf based slide show. 3.1.12 Literate Programming by D. Knuth Literate programming is an approach to programming introduced by Donald Knuth in which a program is given as an explanation of the program logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which a compilable source code can be generated 3.1.12.1 D. Knuth Let us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do. 3.1.13 Reproducible Research - Quote from a Coursera Course 3.1.13.1 Reproducible Research Reproducible research is the idea that data analyses, and more generally, scientific claims, are published with their data and software code so that others may verify the findings and build upon them. The need for reproducibility is increasing dramatically as data analyses become more complex, involving larger datasets and more sophisticated computations. Reproducibility allows for people to focus on the actual content of a data analysis, rather than on superficial details reported in a written summary. In addition, reproducibility makes an analysis more useful to others because the data and code that actually conducted the analysis are available. 3.1.14 R Markdown workflow, R for Data Science R Markdown is also important because it so tightly integrates prose and code. This makes it a great analysis notebook because it lets you develop code and record your thoughts. It: Records what you did and why you did it. Regardless of how great your memory is, if you don’t record what you do, there will come a time when you have forgotten important details. Write them down so you don’t forget! Supports rigorous thinking. You are more likely to come up with a strong analysis if you record your thoughts as you go, and continue to reflect on them. This also saves you time when you eventually write up your analysis to share with others. Helps others understand your work. It is rare to do data analysis by yourself, and you’ll often be working as part of a team. A lab notebook helps you share why you did it with your colleagues or lab mates. 3.1.14.1 Examples of yaml --- title: &quot;R Notebook&quot; output: html_notebook --- 3.1.14.1.1 Default + author + date The format of date can be changed. --- title: &quot;Title of the Notebook&quot; author: &quot;Your Name&quot; date: &quot;2021-12-22&quot; output: html_notebook --- 3.1.14.1.2 Examples 3.1.14.1.3 Notebook of Coronavirus --- title: &quot;A Study of Cases of Coronavirus Pandemic&quot; author: &quot;Hiroshi Suzuki&quot; date: &quot;2021/12/22&quot; output: html_notebook: number_sections: yes toc: yes toc_float: yes --- 3.1.14.1.4 Notebook of Coronavirus + pdf + word --- title: &quot;A Study of Cases of Coronavirus Pandemic&quot; author: &quot;Hiroshi Suzuki&quot; date: &quot;2021/12/22&quot; output: html_notebook: number_sections: yes toc: yes toc_float: yes pdf_document: toc: true number_sections: true word_document: default --- 3.1.14.1.5 Edit the word file file_show.docx to create my-styles.docx, e.g., a4-my-styles.docx changed the paper size to A4 from US letter. --- title: &quot;A Study of Cases of Coronavirus Pandemic&quot; author: &quot;Hiroshi Suzuki&quot; date: &quot;2021/12/22&quot; output: html_notebook: number_sections: yes toc: yes toc_float: yes pdf_document: toc: true number_sections: true word_document: reference_docx: a4-my-styles.docx --- 3.1.15 Learning Resources, EDA2-1 Textbook: R for Data Science, Part V Communicate R Markdown: The Definitive Guide by Yihui Xie, J. J. Allaire, Garrett Grolemund [Last Revised: 2020-12-14] BOOKDOWN: Write HTML, PDF, ePub, and Kindle books with R Markdown. Free online document is provided in pdf as well Arxive Page RMarkdown for Scientists by Nicholas Tierney [Last Revised: 2020-09-09] Report Writing for Data Science in R by Roger Peng Social Science Computing Cooperative at the University of Wisconsin R for Researchers: R Markdown [Last Revised: 2015-04-16] 3.1.16 Practicum: R Markdown and R Notebook Install rmarkdown, tinytex, tidyverse (and timetk) Try RMarkdown: HTML, PDF, Word Try R Notebook: Code Chunk RStudio Help Visual Editor Download from Moodle Export and import files file name.nb.html and file name.Rmd YAML Shared link to RStudio.cloud: https://moodle3.icu.ac.jp/mod/url/view.php?id=185785 NB. Sys.setenv(LANG = \"en\") 3.2 Part II: Data Visualization and Tidyverse Package 3.2.1 Introduction to tidyverse R Packages CRAN: https://cran.r-project.org &gt; Packages (menu) Contributed Packages Currently, the CRAN package repository features 16850 available packages. RStudio: R Packages Quick list of useful R packages Tidyverse: https://www.tidyverse.org Install tidyverse install.packages(“tidyverse”) RStudio Menu: Tools &gt; Install Packages &gt; tidyverse Attaching tidyverse library(tidyverse) The following packages are attached automatically: ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr, forcats 3.2.2 ggplot2 Overview ggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details. Examples ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) ggplot(data = mpg) + geom_boxplot(mapping = aes(x = class, y = hwy)) Template ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;)) 3.2.3 Practicum: ggplot2 on R Notebook library(tidyverse) cars and iris df_cars &lt;- cars, df_iris &lt;- iris geom_point, geom_line, geom_histogram, goem_boxplot aes(), color = () facet_wrap(vars()) Examples in Moodle 3.2.4 Basics of Fundamentals of Statistics 3.2.4.1 R Commands Related to R Basics Fundamentals of Statistics: statistical measurements such as mean: mean() or mean(x, na.rm = TRUE) median: median() or median(x, na.rm = TRUE) quantile: quantile() or quantile(x, na.rm = TRUE) variance: var() or var(x, na.rm = TRUE) standard deviation: sd() covariance: cov() correlation: cor() summary() –&gt; 3.2.5 RStudio Primers created by learnr 3.2.5.1 RStudio Primers https://rstudio.cloud/learn/primers The Basics – r4ds: Explore, I Programming Basics: Try this first! Visualization Basics Work with Data – r4ds: Wrangle, I Working with Tibbles Isolating Data with dplyr Deriving Information with dplyr Visualize Data – r4ds: Explore, II Tidy Your Data – r4ds: Wrangle, II Iterate – r4ds: Program Write Functions – r4ds: Program Report Reproductively – r4ds: Communicate Build Interactive Web Apps – r4ds: Communicate 3.2.6 Learning Resources, EDA2-2 https://rstudio.com/resources/webinars/a-gentle-introduction-to-tidy-statistics-in-r/ Textbook: R for Data Science, Part I Explore RStuio Primers: See References in Moodle at the bottom Stackoverflow https://stackoverflow.com For non-English system users: Set Sys.setenv(LANGUAGE = \"en\"): It is helpful for searching information on the internet when you get an error. Books: R Cookbook, 2nd Edition, James (JD) Long and Paul Teetor: https://rc2e.com Fundamentals of Data Visualization, by Claus O. Wilke: https://clauswilke.com/dataviz/index.html 3.3 The Week Three Assignment (in Moodle) Pick two data from the built-in dataset. (library(help = \"datasets\") or go to the site The R Datasets Package) One of them can be iris but do not choose cars or AirPassengers. ggplot2 examples of cars, iris and AirPassengers are given below. Create an R Notebook of a Data Analysis containing the following and submit the rendered HTML file (file name.nb.html): title, date, and author, i.e., Your Name an explanation of the data and the variables at least one code chunk containing the following: head(), str() for each dataset, at least one code chunk containing graphs using ggplot2. Please try at least two geoms: geom_hist(), geom_boxplot(), goem_col(), etc. geom_line(), geom_point(), etc. your findings and/or questions file name: ID.nb.html, e.g. 123456.nb.html option: median(), mean(), sd() of a quantitative (numeric) variable, cor() of two quantitative (numeric) variables (or a correlation table) Submit your R Notebook file to Moodle (The Third Assignment) by 2021-01-11 23:59:00 3.3.1 Note on R Notebook Please note the following. There are essentially three modes: R Scripts, R Notebook and R Markdown. R Notebook is a special type of R Markdown but please use R Notebook at least for Suzuki’s assignments. To start, choose R Notebook from New File in the File Menu. If you started with R Markdown, please switch it with the Preview button hidden under the triangle on the right of the knit button. The file we preview has the name file name.nb.html. For example if the original file name is a3_12345.Rmd, then a3_12345.nb.html is created. You can check it using Files tab. When you preview R Notebook, on the top right, you can find Code button. If you press it you also can find download Rmd, which is the source of R Notebook you edited. In this way we can share both the outputs and the source. One difficulty is that you cannot include the outputs of the code chunk in the preview. Check Preview on Save and/or save the file before preview, i.e., pressing the preview button. Select Run all under Run button. Then all outputs apear on your editor and all outputs will appear in your preview. If some of your code chunks have problems, run each code chunk from top to bottom so that all outputs appear in your editor or viewer. When you share your R Notebook, do not forget to share file name.nb.html. If you have a file name.nb.html, then find it from Files in R Studio, you can automatically create file name.Rmd to edit the source. To create a fancy document with R Notebook, see the Markdown Quick Reference under Help on top menu for the editor. If you are using Visual Editor using A bottun on top left pane, see https://rstudio.github.io/visual-markdown-editing/. R Studio introduced Visual Editor last year. It seems to be stable but it is not perfect to go back and forth from the original editor using tags. I always use the original editor and I am confident on all the functions of it but I do not have much experience on Visual Editor. 3.3.2 Set up We will use ggplot2 package which is a part of tidyverse package. # install.packages(&quot;tidyverse&quot;) # only once library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.10 ## ✔ tidyr 1.2.1 ✔ stringr 1.4.1 ## ✔ readr 2.1.2 ✔ forcats 0.5.2 ## ── Conflicts ────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() 3.3.3 Data cars We will study the data cars in an R package datasets. Name: Speed and Stopping Distances of Cars Description: The data give the speed of cars and the distances taken to stop. Note that the data were recorded in the 1920s. Source: The data give the speed of cars and the distances taken to stop. Note that the data were recorded in the 1920s. References McNeil, D. R. (1977) Interactive Data Analysis. Wiley. data(cars) # to refresh data, it is better to start with this. df_cars &lt;- cars # You can use cars as is, but it is safer to assign it to other name head(df_cars) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 7 22 ## 5 8 16 ## 6 9 10 str(df_cars) ## &#39;data.frame&#39;: 50 obs. of 2 variables: ## $ speed: num 4 4 7 7 8 9 10 10 10 11 ... ## $ dist : num 2 10 4 22 16 10 18 26 34 17 ... 3.3.3.1 Observations on Data Structure There are two numeric variables of lenght 50: speed, dist 3.3.3.2 Data Visualization by ggplot2 3.3.3.2.1 Scatter Plot by geom_point() ggplot(df_cars) + geom_point(aes(x = speed, y = dist)) + labs(x = &quot;speed (mph)&quot;, y = &quot;dist (ft)&quot;, title = &quot;Speed and Stopping Distances of Cars&quot;) Observation 1 Roughly the dist is proportional to the speed. cor(df_cars) ## speed dist ## speed 1.0000000 0.8068949 ## dist 0.8068949 1.0000000 The correlation is 0.806. So we say strongly correlated. In the following, since the mapping aes() are the same for two geoms, we can place it in ggplot(). We will study linear regression in Week 6 and on. ggplot(df_cars, aes(x = speed, y = dist)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + labs(x = &quot;speed (mph)&quot;, y = &quot;dist (ft)&quot;, title = &quot;Speed and Stopping Distances of Cars&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; summary(lm(df_cars$dist ~ df_cars$speed)) ## ## Call: ## lm(formula = df_cars$dist ~ df_cars$speed) ## ## Residuals: ## Min 1Q Median 3Q Max ## -29.069 -9.525 -2.272 9.215 43.201 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -17.5791 6.7584 -2.601 0.0123 * ## df_cars$speed 3.9324 0.4155 9.464 1.49e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.38 on 48 degrees of freedom ## Multiple R-squared: 0.6511, Adjusted R-squared: 0.6438 ## F-statistic: 89.57 on 1 and 48 DF, p-value: 1.49e-12 3.3.3.2.2 Histograms by geom_histogram() ggplot(df_cars) + geom_histogram(aes(x = speed)) + labs(title = &quot;Histogram of speed&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(df_cars) + geom_histogram(aes(x = speed), binwidth = 1) + labs(title = &quot;Histogram of speed&quot;) ggplot(df_cars) + geom_histogram(aes(x = dist)) + labs(title = &quot;Histogram of speed&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(df_cars) + geom_histogram(aes(x = dist), binwidth = 1) + labs(title = &quot;Histogram of speed&quot;) 3.3.4 Data iris We will study the data iris in an R package datasets. Name: Edgar Anderson’s Iris Data Description: This famous (Fisher’s or Anderson’s) iris data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica. Source: Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7, Part II, 179–188. The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2–5. data(iris) # to refresh data, it is better to start with this. df_iris &lt;- iris # You can use iris as is, but it is safer to assign it to other name head(df_iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa str(df_iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... unique(df_iris$Species) ## [1] setosa versicolor virginica ## Levels: setosa versicolor virginica 3.3.4.1 Observations on Data Structure There are five variables: Sepal.Length, Sepal.Width, Petal.Length, Petal.Width and Species First four variables are numeric, and the fifth is a character vector in factor Species have three levels corresponding to three kinds of iris: setosa versicolor virginica 3.3.4.2 Data Analysis of Each Variable, i.e., Univariate Analysis For geom_histogram the default of stat is “bin” for continuous data. Set stat = \"count\", and adjust the bins by the number of bins, i.e. bins option with 30 for default or biwidth option that overrides bins. ggplot(df_iris) + geom_histogram(aes(x = Sepal.Length)) + labs(title = &quot;Histogram of Sepal.Length&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(df_iris) + geom_histogram(aes(x = Sepal.Length), bins = 10) + labs(title = &quot;Histogram of Sepal.Length&quot;) ggplot(df_iris) + geom_histogram(aes(x = Sepal.Length), binwidth = 0.1) + labs(title = &quot;Histogram of Sepal.Length&quot;) The previous graph is similar to the next. ggplot(df_iris) + geom_histogram(aes(x = Sepal.Length), stat = &quot;count&quot;) + labs(title = &quot;Histogram of Sepal.Length&quot;) ## Warning: Ignoring unknown parameters: binwidth, bins, pad ggplot(df_iris) + geom_histogram(aes(x = Sepal.Length, fill = Species), stat = &quot;count&quot;) + labs(title = &quot;Histogram of Sepal.Length&quot;) ## Warning: Ignoring unknown parameters: binwidth, bins, pad ggplot(df_iris) + geom_histogram(aes(x = Sepal.Length, fill = Species), binwidth = 0.1) + labs(title = &quot;Histogram of Sepal.Length&quot;) ggplot(df_iris) + geom_boxplot(aes(x = Species, y = Sepal.Length)) + labs(title = &quot;Boxplot of Sepal.Lenght&quot;) ggplot(df_iris) + geom_boxplot(aes(x = Species, y = Sepal.Width)) + labs(title = &quot;Boxplot of Sepal.Width&quot;) ggplot(df_iris) + geom_boxplot(aes(x = Species, y = Petal.Length)) + labs(title = &quot;Boxplot of Petal.Length&quot;) ggplot(df_iris) + geom_boxplot(aes(x = Species, y = Petal.Width)) + labs(title = &quot;Boxplot of Petal.Width&quot;) 3.3.4.3 Data Analysis of Two Variables, i.e., Multivariate Analysis The following is a simple scatter plot. However, from the univariate analysis, it is clear that Species are key factors. ggplot(df_iris) + geom_point(aes(x = Sepal.Length, y = Sepal.Width)) ggplot(df_iris) + geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species)) ggplot(df_iris) + geom_point(aes(x = Sepal.Length, y = Sepal.Width)) + facet_wrap(vars(Species)) Let us check the correlation matrix cor(df_iris[,1:4]) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length 1.0000000 -0.1175698 0.8717538 0.8179411 ## Sepal.Width -0.1175698 1.0000000 -0.4284401 -0.3661259 ## Petal.Length 0.8717538 -0.4284401 1.0000000 0.9628654 ## Petal.Width 0.8179411 -0.3661259 0.9628654 1.0000000 Petal.Length and Petal.Width have very strong positive correlation, and so are Sepal.Length and Petal.Length. Sepal.Width and Petal.Length have weak negative correlation, and so are Sepal.Width and Petal.Width. ggplot(df_iris) + geom_point(aes(x = Petal.Length, y = Petal.Width, color = Species)) ggplot(df_iris) + geom_point(aes(x = Petal.Length, y = Petal.Width)) + facet_wrap(vars(Species)) ggplot(df_iris) + geom_point(aes(x = Sepal.Length, y = Petal.Length, color = Species)) ggplot(df_iris) + geom_point(aes(x = Sepal.Length, y = Petal.Length)) + facet_wrap(vars(Species)) ggplot(df_iris) + geom_point(aes(x = Sepal.Width, y = Petal.Length, color = Species)) ggplot(df_iris) + geom_point(aes(x = Sepal.Width, y = Petal.Length)) + facet_wrap(vars(Species)) ggplot(df_iris) + geom_point(aes(x = Sepal.Width, y = Petal.Width, color = Species)) ggplot(df_iris) + geom_point(aes(x = Sepal.Width, y = Petal.Width)) + facet_wrap(vars(Species)) As we have seen above the situation is more complicated. Observation: Altogether Sepal.Width and Petal.Width have a negative correlation. However, if we look at the graph for each, they seem to have a positive correlation. In statistics we say that the Species is the confounder. 3.3.5 Data AirPassengers Next, we look at the data AirPassengers in an R package datasets. Name: Monthly Airline Passenger Numbers 1949-1960 Description: The classic Box &amp; Jenkins airline data. Monthly totals of international airline passengers, 1949 to 1960. Source: Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976) Time Series Analysis, Forecasting and Control. Third Edition. Holden-Day. Series G. data(AirPassengers) # to refresh data, it is better to start with this. df_AirPassengers &lt;- AirPassengers # You can use iris as is, but it is safer to assign it to other name head(df_AirPassengers) ## [1] 112 118 132 129 121 135 str(df_AirPassengers) ## Time-Series [1:144] from 1949 to 1961: 112 118 132 129 121 135 148 148 136 119 ... This is a time series data, a special data format of Base R. plot(df_AirPassengers) We can handle this type of data using tidyverse but now it is easier to use the following package. timetk Package https://CRAN.R-project.org/package=timetk # install.packages(&quot;timetk&quot;) # run this line or install `timetk` from Install Packages in Tool library(timetk) df_ap &lt;- tk_tbl(df_AirPassengers) df_ap ## # A tibble: 144 × 2 ## index value ## &lt;yearmon&gt; &lt;dbl&gt; ## 1 1 1949 112 ## 2 2 1949 118 ## 3 3 1949 132 ## 4 4 1949 129 ## 5 5 1949 121 ## 6 6 1949 135 ## 7 7 1949 148 ## 8 8 1949 148 ## 9 9 1949 136 ## 10 10 1949 119 ## # … with 134 more rows ggplot(df_ap) + geom_line(aes(x = index, y = value)) + labs(title = &quot;Line Graph of AirPassengers&quot;) Observation: There is a seasonal pattern. ggplot(df_ap) + geom_histogram(aes(x = value)) + labs(title = &quot;Histogram of AirPassengers&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 3.3.6 Recommended Study Plan Review the class note, slides and/or videos RStudio Primers: Programming Basics, and Visualization Basics Review this note Look at The R Datasets Package) or in Console, library(help = \"datasets\") and use Help to check each data in the built-in datasets. Try this assignment Study the chapters 1-8 under Explore in the textbook. 3.4 Responses to the Week Three Assignment 3.4.1 Setup We load two packages; datasets and ggplot2. The datasets are loaded automatically and you do not need the first line of the followiong code chunk. But it is safer to include it because some data names are used previously for different purposes. library(datasets) library(ggplot2) For explanation, we use the following population data of WDI. library(WDI) pop &lt;- WDI( country = c(&quot;NG&quot;, &quot;BD&quot;, &quot;RU&quot;, &quot;MX&quot;, &quot;JP&quot;), indicator = c(population = &quot;SP.POP.TOTL&quot;), start = 1960, end = 2020) head(pop) ## iso2c country population year ## 1 BD Bangladesh 164689383 2020 ## 2 BD Bangladesh 163046173 2019 ## 3 BD Bangladesh 161376713 2018 ## 4 BD Bangladesh 159685421 2017 ## 5 BD Bangladesh 157977151 2016 ## 6 BD Bangladesh 156256287 2015 3.4.2 Visualization of Two Variables iris_df &lt;- iris str(iris_df) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... head(iris_df) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Let us look at two plots, one with geom_point() and the other with geom_line() ggplot(iris_df) + geom_point(mapping = aes(x=Petal.Length, y=Petal.Width)) ggplot(iris_df) + geom_line(mapping = aes(x=Petal.Length, y=Petal.Width)) The line graph is not appropriate. Can you see why? By help(geom_line) or Help tab with geom_line in the search window, we get the following: geom_line() connects them in order of the variable on the x axis. See https://ggplot2.tidyverse.org/reference/geom_path.html In this case lines are meaningless especially the vertical lines. ggplot(iris_df) + geom_point(mapping = aes(x=Petal.Length, y=Petal.Width, color = Species)) ggplot(iris_df) + geom_line(mapping = aes(x=Petal.Length, y=Petal.Width, color = Species)) It is good to add colors for Species in geom_point, however, geom_line is not appropriate in this case. Let us look at the population data of WDI. ggplot(pop) + geom_point(mapping = aes(x=year, y=population)) This is OK. ggplot(pop) + geom_line(mapping = aes(x=year, y=population)) We have a similar problem with geom_line(). However, ggplot(pop) + geom_line(mapping = aes(x=year, y=population, color = country)) This looks just fine. In this case geom_line() with color aestic is better than geom_point() above. If you have two numerical data, it is safer to use geom_point() first and decide to choose a better option. It is not easy to decide whether the lines between the points are meaningful or not. Please think carefully what you want to communicate. In some cases, you may want to choose the following. Note that I moved the aes() to ggplot() as it is common to both geom_line() and geom_point(). ggplot(pop, mapping = aes(x=year, y=population, color = country)) + geom_line() + geom_point() See other examples df_tg &lt;- ToothGrowth head(df_tg) ## len supp dose ## 1 4.2 VC 0.5 ## 2 11.5 VC 0.5 ## 3 7.3 VC 0.5 ## 4 5.8 VC 0.5 ## 5 6.4 VC 0.5 ## 6 10.0 VC 0.5 str(df_tg) ## &#39;data.frame&#39;: 60 obs. of 3 variables: ## $ len : num 4.2 11.5 7.3 5.8 6.4 10 11.2 11.2 5.2 7 ... ## $ supp: Factor w/ 2 levels &quot;OJ&quot;,&quot;VC&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ dose: num 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... ggplot(df_tg) + geom_point(aes(x = dose, y = len, color = supp)) ggplot(df_tg) + geom_boxplot(aes(x = factor(dose), y = len)) + facet_wrap(vars(supp)) 3.4.3 Visualization of One Variable df_chickwts &lt;- chickwts df_chickwts ## weight feed ## 1 179 horsebean ## 2 160 horsebean ## 3 136 horsebean ## 4 227 horsebean ## 5 217 horsebean ## 6 168 horsebean ## 7 108 horsebean ## 8 124 horsebean ## 9 143 horsebean ## 10 140 horsebean ## 11 309 linseed ## 12 229 linseed ## 13 181 linseed ## 14 141 linseed ## 15 260 linseed ## 16 203 linseed ## 17 148 linseed ## 18 169 linseed ## 19 213 linseed ## 20 257 linseed ## 21 244 linseed ## 22 271 linseed ## 23 243 soybean ## 24 230 soybean ## 25 248 soybean ## 26 327 soybean ## 27 329 soybean ## 28 250 soybean ## 29 193 soybean ## 30 271 soybean ## 31 316 soybean ## 32 267 soybean ## 33 199 soybean ## 34 171 soybean ## 35 158 soybean ## 36 248 soybean ## 37 423 sunflower ## 38 340 sunflower ## 39 392 sunflower ## 40 339 sunflower ## 41 341 sunflower ## 42 226 sunflower ## 43 320 sunflower ## 44 295 sunflower ## 45 334 sunflower ## 46 322 sunflower ## 47 297 sunflower ## 48 318 sunflower ## 49 325 meatmeal ## 50 257 meatmeal ## 51 303 meatmeal ## 52 315 meatmeal ## 53 380 meatmeal ## 54 153 meatmeal ## 55 263 meatmeal ## 56 242 meatmeal ## 57 206 meatmeal ## 58 344 meatmeal ## 59 258 meatmeal ## 60 368 casein ## 61 390 casein ## 62 379 casein ## 63 260 casein ## 64 404 casein ## 65 318 casein ## 66 352 casein ## 67 359 casein ## 68 216 casein ## 69 222 casein ## 70 283 casein ## 71 332 casein ggplot(df_chickwts) + geom_point(aes(x = feed, y = weight)) ggplot(df_chickwts) + geom_boxplot(aes(x = feed, y = weight)) Since there are two variables, you can use geom_point(). However, one of them is a categorical variable and box_plot() works better, I believe. It is called a box and whiskers plot (in the style of Turkey). Please look at Help. The boxplot compactly displays the distribution of a continuous variable. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually. See also https://ggplot2.tidyverse.org/reference/geom_boxplot.html. The other popular visualization is geom_histogram(). Please try fill and color options to see the difference. ggplot(df_chickwts) + geom_histogram(aes(x = weight, fill = feed)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(df_chickwts) + geom_freqpoly(aes(x = weight, color = feed)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(df_chickwts) + geom_histogram(aes(x = weight), bins = 10) + facet_wrap(vars(feed)) Which one do you like best? There are many options. Again, it depends on what you want to communicate. # `rivers` is a numeric vector, so changed into a dataframe. df_riv &lt;- data.frame(length = rivers) # it is safer to assign it to other name head(df_riv) ## length ## 1 735 ## 2 320 ## 3 325 ## 4 392 ## 5 524 ## 6 450 Since there is no meaning in ordering, geom_histogram() may be an appropriate choice. ggplot(df_riv, aes(length)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 3.4.4 More Examples 3.4.4.1 Weight versus age of chicks on different diets Description: The ChickWeight data frame has 578 rows and 4 columns from an experiment on the effect of diet on early growth of chicks. Format: An object of class c(“nfnGroupedData”, “nfGroupedData”, “groupedData”, “data.frame”) containing the following columns: weight: a numeric vector giving the body weight of the chick (gm). Time: a numeric vector giving the number of days since birth when the measurement was made. Chick: an ordered factor with levels 18 &lt; … &lt; 48 giving a unique identifier for the chick. The ordering of the levels groups chicks on the same diet together and orders them according to their final weight (lightest to heaviest) within diet. Diet: a factor with levels 1, …, 4 indicating which experimental diet the chick received. Details: The body weights of the chicks were measured at birth and every second day thereafter until day 20. They were also measured on day 21. There were four groups on chicks on different protein diets. df_chickweight &lt;- ChickWeight head(df_chickweight) ## Grouped Data: weight ~ Time | Chick ## weight Time Chick Diet ## 1 42 0 1 1 ## 2 51 2 1 1 ## 3 59 4 1 1 ## 4 64 6 1 1 ## 5 76 8 1 1 ## 6 93 10 1 1 str(df_chickweight) ## Classes &#39;nfnGroupedData&#39;, &#39;nfGroupedData&#39;, &#39;groupedData&#39; and &#39;data.frame&#39;: 578 obs. of 4 variables: ## $ weight: num 42 51 59 64 76 93 106 125 149 171 ... ## $ Time : num 0 2 4 6 8 10 12 14 16 18 ... ## $ Chick : Ord.factor w/ 50 levels &quot;18&quot;&lt;&quot;16&quot;&lt;&quot;15&quot;&lt;..: 15 15 15 15 15 15 15 15 15 15 ... ## $ Diet : Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## - attr(*, &quot;formula&quot;)=Class &#39;formula&#39; language weight ~ Time | Chick ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;outer&quot;)=Class &#39;formula&#39; language ~Diet ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;labels&quot;)=List of 2 ## ..$ x: chr &quot;Time&quot; ## ..$ y: chr &quot;Body weight&quot; ## - attr(*, &quot;units&quot;)=List of 2 ## ..$ x: chr &quot;(days)&quot; ## ..$ y: chr &quot;(gm)&quot; summary(df_chickweight) ## weight Time Chick Diet ## Min. : 35.0 Min. : 0.00 13 : 12 1:220 ## 1st Qu.: 63.0 1st Qu.: 4.00 9 : 12 2:120 ## Median :103.0 Median :10.00 20 : 12 3:120 ## Mean :121.8 Mean :10.72 10 : 12 4:118 ## 3rd Qu.:163.8 3rd Qu.:16.00 17 : 12 ## Max. :373.0 Max. :21.00 19 : 12 ## (Other):506 ggplot(df_chickweight) + geom_point(aes(x = Time, y = weight, color = Diet)) If we use dplyr(), we can summarize the mean, i.e., average weight in each category. library(dplyr) df_chickweight %&gt;% group_by(Diet, Time) %&gt;% summarize(wt = mean(weight)) %&gt;% ggplot() + geom_line(aes(x = Time, y = wt, color = Diet)) ## `summarise()` has grouped output by &#39;Diet&#39;. You can override using the `.groups` ## argument. If we use geom_smooth(), we can plot the smoothed conditional means. See https://ggplot2.tidyverse.org/reference/geom_smooth.html. ggplot(df_chickweight) + geom_smooth(aes(x = Time, y = weight, color = Diet)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 3.4.4.2 Carbon Dioxide Uptake in Grass Plants Description: The CO2 data frame has 84 rows and 5 columns of data from an experiment on the cold tolerance of the grass species Echinochloa crus-galli. Usage: CO2 Format: An object of class c(“nfnGroupedData”, “nfGroupedData”, “groupedData”, “data.frame”) containing the following columns: Plant an ordered factor with levels Qn1 &lt; Qn2 &lt; Qn3 &lt; … &lt; Mc1 giving a unique identifier for each plant. Type a factor with levels Quebec Mississippi giving the origin of the plant Treatment a factor with levels nonchilled chilled conc a numeric vector of ambient carbon dioxide concentrations (mL/L). uptake a numeric vector of carbon dioxide uptake rates (umol/m^2 sec). Details The CO2 uptake of six plants from Quebec and six plants from Mississippi was measured at several levels of ambient CO2 concentration. Half the plants of each type were chilled overnight before the experiment was conducted. df_CO2 &lt;- CO2 head(df_CO2) ## Grouped Data: uptake ~ conc | Plant ## Plant Type Treatment conc uptake ## 1 Qn1 Quebec nonchilled 95 16.0 ## 2 Qn1 Quebec nonchilled 175 30.4 ## 3 Qn1 Quebec nonchilled 250 34.8 ## 4 Qn1 Quebec nonchilled 350 37.2 ## 5 Qn1 Quebec nonchilled 500 35.3 ## 6 Qn1 Quebec nonchilled 675 39.2 str(df_CO2) ## Classes &#39;nfnGroupedData&#39;, &#39;nfGroupedData&#39;, &#39;groupedData&#39; and &#39;data.frame&#39;: 84 obs. of 5 variables: ## $ Plant : Ord.factor w/ 12 levels &quot;Qn1&quot;&lt;&quot;Qn2&quot;&lt;&quot;Qn3&quot;&lt;..: 1 1 1 1 1 1 1 2 2 2 ... ## $ Type : Factor w/ 2 levels &quot;Quebec&quot;,&quot;Mississippi&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Treatment: Factor w/ 2 levels &quot;nonchilled&quot;,&quot;chilled&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ conc : num 95 175 250 350 500 675 1000 95 175 250 ... ## $ uptake : num 16 30.4 34.8 37.2 35.3 39.2 39.7 13.6 27.3 37.1 ... ## - attr(*, &quot;formula&quot;)=Class &#39;formula&#39; language uptake ~ conc | Plant ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;outer&quot;)=Class &#39;formula&#39; language ~Treatment * Type ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;labels&quot;)=List of 2 ## ..$ x: chr &quot;Ambient carbon dioxide concentration&quot; ## ..$ y: chr &quot;CO2 uptake rate&quot; ## - attr(*, &quot;units&quot;)=List of 2 ## ..$ x: chr &quot;(uL/L)&quot; ## ..$ y: chr &quot;(umol/m^2 s)&quot; summary(df_CO2) ## Plant Type Treatment conc uptake ## Qn1 : 7 Quebec :42 nonchilled:42 Min. : 95 Min. : 7.70 ## Qn2 : 7 Mississippi:42 chilled :42 1st Qu.: 175 1st Qu.:17.90 ## Qn3 : 7 Median : 350 Median :28.30 ## Qc1 : 7 Mean : 435 Mean :27.21 ## Qc3 : 7 3rd Qu.: 675 3rd Qu.:37.12 ## Qc2 : 7 Max. :1000 Max. :45.50 ## (Other):42 ggplot(df_CO2) + geom_point(aes(x = conc, y = uptake, color = Type)) + facet_wrap(vars(Treatment)) ggplot(df_CO2) + geom_smooth(aes(x = conc, y = uptake, color = Type)) + facet_wrap(vars(Treatment)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 3.4.4.3 Growth of Orange Trees Description: The Orange data frame has 35 rows and 3 columns of records of the growth of orange trees. Usage: Orange Format: An object of class c(“nfnGroupedData”, “nfGroupedData”, “groupedData”, “data.frame”) containing the following columns: Tree an ordered factor indicating the tree on which the measurement is made. The ordering is according to increasing maximum diameter. age a numeric vector giving the age of the tree (days since 1968/12/31) circumference a numeric vector of trunk circumferences (mm). This is probably “circumference at breast height”, a standard measurement in forestry. Details: This dataset was originally part of package nlme, and that has methods (including for [, as.data.frame, plot and print) for its grouped-data classes. df_orange &lt;- Orange head(df_orange) ## Grouped Data: circumference ~ age | Tree ## Tree age circumference ## 1 1 118 30 ## 2 1 484 58 ## 3 1 664 87 ## 4 1 1004 115 ## 5 1 1231 120 ## 6 1 1372 142 str(df_orange) ## Classes &#39;nfnGroupedData&#39;, &#39;nfGroupedData&#39;, &#39;groupedData&#39; and &#39;data.frame&#39;: 35 obs. of 3 variables: ## $ Tree : Ord.factor w/ 5 levels &quot;3&quot;&lt;&quot;1&quot;&lt;&quot;5&quot;&lt;&quot;2&quot;&lt;..: 2 2 2 2 2 2 2 4 4 4 ... ## $ age : num 118 484 664 1004 1231 ... ## $ circumference: num 30 58 87 115 120 142 145 33 69 111 ... ## - attr(*, &quot;formula&quot;)=Class &#39;formula&#39; language circumference ~ age | Tree ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;labels&quot;)=List of 2 ## ..$ x: chr &quot;Time since December 31, 1968&quot; ## ..$ y: chr &quot;Trunk circumference&quot; ## - attr(*, &quot;units&quot;)=List of 2 ## ..$ x: chr &quot;(days)&quot; ## ..$ y: chr &quot;(mm)&quot; summary(df_orange) ## Tree age circumference ## 3:7 Min. : 118.0 Min. : 30.0 ## 1:7 1st Qu.: 484.0 1st Qu.: 65.5 ## 5:7 Median :1004.0 Median :115.0 ## 2:7 Mean : 922.1 Mean :115.9 ## 4:7 3rd Qu.:1372.0 3rd Qu.:161.5 ## Max. :1582.0 Max. :214.0 ggplot(df_orange) + geom_point(aes(x = age, y = circumference, color = Tree)) ggplot(df_orange) + geom_boxplot(aes(x = factor(age), y = circumference)) ggplot(df_orange) + geom_smooth(aes(x = age, y = circumference)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; "]]
